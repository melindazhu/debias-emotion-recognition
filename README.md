# **Detecting and Mitigating Bias in Face Emotion Recognition Models**  

### **ğŸ‘¥ Students:** Basant Khalil & Melinda Zhu  

---

## **ğŸ“Œ Project Overview**  

Facial emotion recognition (FER) models are widely used in fields such as human-computer interaction, security, and psychology. However, these models often exhibit **racial and ethnic biases** due to imbalanced datasets, leading to **unfair predictions** across different demographic groups.  

Our project aims to:  
âœ” Train a **baseline emotion classification model** using real-world datasets.  
âœ” **Evaluate bias** in emotion recognition across racial and ethnic groups.  
âœ” Implement **bias mitigation strategies** to enhance fairness in FER models.  

By integrating **RAF-DB** (emotion-labeled dataset) with **FairFace** (race-labeled dataset), we create a more balanced dataset for **bias-aware facial emotion classification**.  

---

## **ğŸ“– Background**  

Studies show significant racial and gender biases in commercial **FER models**. For example:  

ğŸ”¹ **Buolamwini & Gebru (2018)**: Found racial biases in face analysis systems.  
ğŸ”¹ **Zhang et al. (2018)**: Proposed **adversarial debiasing** to mitigate bias.  

### **ğŸ§‘â€ğŸ’» Why does this bias exist?**  
- **Imbalanced datasets** â†’ Certain racial groups are underrepresented.  
- **Feature learning issues** â†’ Models may encode **racial attributes** instead of emotion-based patterns.  
- **Historical biases in AI** â†’ Pretrained models often inherit bias from their training data.  

Our project plans to **quantify and mitigate** these biases using fairness-aware learning techniques.  

---

## **ğŸ›  Methodology**  

### **1ï¸âƒ£ Data Processing**  
âœ” **Assign race labels** to the RAF-DB dataset using FairFace.  
âœ” **Extract face embeddings** using **FaceNet** for race-label matching.  

### **2ï¸âƒ£ Baseline Model Training**  
âœ” Train a **ResNet**/**MobileNet** model on **RAF-DB**.  
âœ” Evaluate bias across racial groups using:  
   - **Per-class accuracy**  
   - **False positive/negative rates**  
   - **Disparate impact & statistical parity difference**  

### **3ï¸âƒ£ Bias Mitigation Techniques**  
âœ” Implement **fairness-aware adversarial networks** to remove race-sensitive features.  
âœ” Retrain the model and **recompute fairness metrics**.  

---

## **ğŸ“‚ Directory Structure**  

```bash
Face_Emotion_Bias_Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ RAF_DB/          # RAF-DB dataset (emotion labels)
â”‚   â”œâ”€â”€ FairFace/        # FairFace dataset (race/ethnicity labels)
â”‚   â””â”€â”€ README.md        # Dataset details
â”œâ”€â”€ outputs/  
â”‚   â”œâ”€â”€ raf_embeddings.npy      # Processed face embeddings  
â”‚   â”œâ”€â”€ raf_labels.npy          # Processed race & emotion labels  
â”‚   â”œâ”€â”€ fairness_results.csv    # Bias evaluation results  
â”‚   â””â”€â”€ README.md               # Output explanations  
â”œâ”€â”€ code/  
â”‚   â”œâ”€â”€ data_processing.py  # Preprocess datasets & extract embeddings  
â”‚   â”œâ”€â”€ baseline_model.py   # Train baseline emotion model  
â”‚   â”œâ”€â”€ bias_mitigation.py  # Implement bias mitigation techniques  
â”‚   â””â”€â”€ README.md           # Code structure explanation  
â”œâ”€â”€ requirements.txt   # Required Python packages  
â”œâ”€â”€ README.md          # Project overview & setup instructions  
â””â”€â”€ .gitignore         # Ignore large files (e.g., datasets)
```

---
# ğŸš€ Setup Instructions  

### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/yourusername/Face_Emotion_Bias_Project.git
cd Face_Emotion_Bias_Project
```

### 2ï¸âƒ£ Create a Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows, use venv\Scripts\activate
```

