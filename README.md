# **Detecting and Mitigating Bias in Face Emotion Recognition Models**  

### **ğŸ‘¥ Students:** Basant Khalil & Melinda Zhu  

---

## **ğŸ“Œ Project Overview**  

Facial emotion recognition (FER) models are widely used in fields such as human-computer interaction, security, and psychology. However, these models often exhibit **racial and ethnic biases** due to imbalanced datasets, leading to **unfair predictions** across different demographic groups.  

Our project aims to:  
âœ” Train a **baseline emotion classification model** using real-world datasets.  
âœ” **Evaluate bias** in emotion recognition across racial and ethnic groups.  
âœ” Implement **bias mitigation strategies** to enhance fairness in FER models.  

By integrating **RAF-DB** (emotion-labeled dataset) with **FairFace** (race-labeled dataset), we create a more balanced dataset for **bias-aware facial emotion classification**.  

---

## **ğŸ“– Background**  

Studies show significant racial and gender biases in commercial **FER models**. For example:  

ğŸ”¹ **Buolamwini & Gebru (2018)**: Found racial biases in face analysis systems.  
ğŸ”¹ **Zhang et al. (2018)**: Proposed **adversarial debiasing** to mitigate bias.  

### **ğŸ§‘â€ğŸ’» Why does this bias exist?**  
- **Imbalanced datasets** â†’ Certain racial groups are underrepresented.  
- **Feature learning issues** â†’ Models may encode **racial attributes** instead of emotion-based patterns.  
- **Historical biases in AI** â†’ Pretrained models often inherit bias from their training data.  

Our project plans to **quantify and mitigate** these biases using fairness-aware learning techniques.  

---

## **ğŸ›  Methodology**  

### **1ï¸âƒ£ Data Processing**  
âœ” **Assign race labels** to the RAF-DB dataset using FairFace.  
âœ” **Extract face embeddings** using **FaceNet** for race-label matching.  

### **2ï¸âƒ£ Baseline Model Training**  
âœ” Train a **ResNet**/**MobileNet** model on **RAF-DB**.  
âœ” Evaluate bias across racial groups using:  
   - **Per-class accuracy**  
   - **False positive/negative rates**  
   - **Disparate impact & statistical parity difference**  

### **3ï¸âƒ£ Bias Mitigation Techniques**  
âœ” Implement **fairness-aware adversarial networks** to remove race-sensitive features.  
âœ” Retrain the model and **recompute fairness metrics**.  

---

## **ğŸ“‚ Directory Structure**  

```bash
Face_Emotion_Bias_Project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ RAF_DB/          # RAF-DB dataset (emotion labels)
â”‚   â”œâ”€â”€ FairFace/        # FairFace dataset (race/ethnicity labels)
â”‚   â””â”€â”€ README.md        # Dataset details
â”œâ”€â”€ outputs/  
â”‚   â”œâ”€â”€ raf_embeddings.npy      # Processed face embeddings  
â”‚   â”œâ”€â”€ raf_labels.npy          # Processed race & emotion labels  
â”‚   â”œâ”€â”€ fairness_results.csv    # Bias evaluation results  
â”‚   â””â”€â”€ README.md               # Output explanations  
â”œâ”€â”€ code/  
â”‚   â”œâ”€â”€ data_processing.py  # Preprocess datasets & extract embeddings  
â”‚   â”œâ”€â”€ baseline_model.py   # Train baseline emotion model  
â”‚   â”œâ”€â”€ bias_mitigation.py  # Implement bias mitigation techniques  
â”‚   â””â”€â”€ README.md         
â”œâ”€â”€ requirements.txt   # Python packages  
â”œâ”€â”€ README.md          # Project overview & setup instructions  
â””â”€â”€ .gitignore         # Ignore large files (e.g., datasets)
```

---
# ğŸš€ Setup Instructions  

### 1ï¸âƒ£ Clone the Repository  
```bash
git clone https://github.com/yourusername/Face_Emotion_Bias_Project.git
cd Face_Emotion_Bias_Project
```

### 2ï¸âƒ£ Create a Virtual Environment
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows, use venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Download the Datasets
- **RAF-DB**: Download and place in `data/RAF_DB/`.  
- **FairFace**: Download and place in `data/FairFace/`. 

### 5ï¸âƒ£ Run the Data Processing Script
```bash
python code/data_processing.py
```
This will process **RAF-DB**, assign **race labels**, and save embeddings in `outputs/`.  


### 6ï¸âƒ£ Train the Baseline Model
```bash
python code/baseline_model.py
```
This will train a **ResNet/MobileNet model** and output evaluation results.  


### 7ï¸âƒ£ Implement Bias Mitigation
```bash
python code/bias_mitigation.py
```
This will apply **adversarial debiasing** and recompute fairness metrics.  

---

# ğŸ“‘ File Descriptions  

### ğŸ“ `data/`  
- `RAF_DB/` â†’ **Emotion-labeled dataset** (happiness, sadness, etc.).  
- `FairFace/` â†’ **Race-labeled dataset** for bias correction.  
- `README.md` â†’ Dataset overview.  

### ğŸ“ `outputs/`  
- `raf_embeddings.npy` â†’ **Face embeddings from FaceNet**.  
- `raf_labels.npy` â†’ **Race and emotion labels**.  
- `fairness_results.csv` â†’ **Bias evaluation metrics**.  
- `README.md` â†’ Output files explanation.  

### ğŸ“ `code/`  
- `data_processing.py` â†’ **Preprocess datasets & generate embeddings**.  
- `baseline_model.py` â†’ **Train a baseline emotion model**.  
- `bias_mitigation.py` â†’ **Implement fairness-aware adversarial debiasing**.  
- `README.md` 

### ğŸ“„ `requirements.txt`  
Contains Python dependencies (e.g., `torch`, `facenet-pytorch`, `opencv-python`).  

### ğŸ“„ `.gitignore`  
Ignores large files like datasets from being committed.  

---

# âš ï¸ Notes  
- Ensure datasets are stored in `data/RAF_DB/` and `data/FairFace/`.  
- Experiment with additional bias mitigation techniques.  
- If you encounter issues, open a **GitHub issue**.  

---

# ğŸ“ License  
This project is licensed under the **MIT License**. See `LICENSE` for details.  
